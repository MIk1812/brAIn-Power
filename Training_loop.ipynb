{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "colab": {
   "name": "Training_loop.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0NC_DRUkJA3",
    "outputId": "e667beb8-d9bd-43f3-8e7f-3afc581f78b5"
   },
   "source": [
    "# Define environment variables \n",
    "%env DEEP_ROOT=/content/drive/My Drive/brAIn-Power\n",
    "%env DEEP_DATA=/content/drive/My Drive/correct_data\n",
    "\n",
    "# Connect to drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Change directory before importing files\n",
    "import os\n",
    "deep_root = os.getenv(\"DEEP_ROOT\")\n",
    "%cd $deep_root\n",
    "\n",
    "!pip install import-ipynb\n",
    "import import_ipynb"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "env: DEEP_ROOT=/content/drive/My Drive/brAIn-Power\n",
      "env: DEEP_DATA=/content/drive/My Drive/correct_data\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HLDUT7-Hj4a_"
   },
   "source": [
    "from LoadData import CustomDataset, load_data_2np,one_hot_encode,one_hot2_2d\n",
    "import UNet\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b74H8Pd1MH0y"
   },
   "source": [
    "# Define some helper functions for later:\n",
    "def IoU_score(target, prediction):\n",
    "  iou_score = 0\n",
    "  for i in range(target.shape[0]):\n",
    "    target[i] = np.argmax(target[i])\n",
    "    prediction[i] = np.argmax(prediction[i])\n",
    "    intersection = np.logical_and(target[i], prediction[i])\n",
    "    union = np.logical_or(target[i], prediction[i])\n",
    "    iou_score += np.sum(intersection) / np.sum(union)\n",
    "  iou_score = iou_score/target.shape[0]\n",
    "  return iou_score"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "44WNr5gLT7S9"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "H_SOSBePj4bF"
   },
   "source": [
    "# Load data the first time\n",
    "#X_train, Y_train, X_valid, Y_valid, X_trans, Y_trans, X_test, Y_test = load_data_2np(hot_encoding=True, valid_perc=0.1, train_perc=0.1,show=0,CAD_perc=0,background=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FlAn_v3ssl5i"
   },
   "source": [
    "Valid_perc = 0.1\n",
    "\n",
    "X_train = np.load(f\"data/compressed_data/with_background/X_train,.npy\")\n",
    "Y_train = np.load(f\"data/compressed_data/with_background/Y_train,.npy\")\n",
    "X_test = np.load(f\"data/compressed_data/with_background/X_test,.npy\")\n",
    "Y_test = np.load(f\"data/compressed_data/with_background/Y_test,.npy\")\n",
    "\n",
    "Y_train = one_hot_encode(imgs=Y_train)\n",
    "Y_test = one_hot_encode(imgs=Y_test)\n",
    "\n",
    "idx = int(Valid_perc*X_train.shape[0])\n",
    "X_valid = X_train[0:idx]\n",
    "X_train = X_train[idx::]\n",
    "\n",
    "Y_valid = Y_train[0:idx]\n",
    "Y_train = Y_train[idx::]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CTK8Lay7ixt5"
   },
   "source": [
    "# Save data for easier load next time - remember to name accodingly\n",
    "# The naming scheme refers pparameters of the load_data_2np function\n",
    "#np.save(\"data/X_train_hot_v0.1_t0.1_s0_c0_True\", X_train)\n",
    "#np.save(\"data/Y_train_hot_v0.1_t0.1_s0_c0_True\", Y_train)\n",
    "#np.save(\"data/X_valid_hot_v0.1_t0.1_s0_c0_True\", X_valid)\n",
    "#np.save(\"data/Y_valid_hot_v0.1_t0.1_s0_c0_True\", Y_valid)\n",
    "#np.save(\"data/X_trans_hot_v0.1_t0.1_s0_c0_True\", X_trans)\n",
    "#np.save(\"data/Y_trans_hot_v0.1_t0.1_s0_c0_True\", Y_trans)\n",
    "#np.save(\"data/X_test_hot_v0.1_t0.1_s0_c0_True\", X_test)\n",
    "#np.save(\"data/Y_test_hot_v0.1_t0.1_s0_c0_True\", Y_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0fRj1OIfkClg"
   },
   "source": [
    "# # Load dataset from .npy files\n",
    "# data_set = \"hot_v0.1_t0.1_s0_c0_True\"\n",
    "\n",
    "# X_train = np.load(f\"data/X_train_{data_set}.npy\")\n",
    "# Y_train = np.load(f\"data/Y_train_{data_set}.npy\")\n",
    "# X_valid = np.load(f\"data/X_valid_{data_set}.npy\")\n",
    "# Y_valid = np.load(f\"data/Y_valid_{data_set}.npy\")\n",
    "# X_test = np.load(f\"data/X_test_{data_set}.npy\")\n",
    "# Y_test = np.load(f\"data/Y_test_{data_set}.npy\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JZ6JSLhnnoK1"
   },
   "source": [
    "# Load transformations if needed\n",
    "#X_trans = np.load(f\"data/X_trans_{data_set}.npy\")\n",
    "#Y_trans = np.load(f\"data/Y_trans_{data_set}.npy\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R5UfVAL5l3rv"
   },
   "source": [
    "DS_train = CustomDataset(X_train, Y_train, one_hot=True)\n",
    "DS_valid = CustomDataset(X_valid, Y_valid, one_hot=True)\n",
    "DS_test = CustomDataset(X_test, Y_test, one_hot=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HJq1OHm1pSqs"
   },
   "source": [
    "# Clear space\n",
    "del X_train\n",
    "del Y_train\n",
    "del X_valid\n",
    "del Y_valid\n",
    "del X_test\n",
    "del Y_test"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WI8cjBmTj4bG"
   },
   "source": [
    "# Perform preprocessing\n",
    "# DS_train.gray_gamma_enhanced()\n",
    "# DS_valid.gray_gamma_enhanced()\n",
    "# DS_test.gray_gamma_enhanced()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gh0MGficb68K"
   },
   "source": [
    "# Check if GPU is available and functions to convert Tensors to Cuda\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uAFj6axTj4bH"
   },
   "source": [
    "# Load in model\n",
    "%%capture\n",
    "net = UNet.UNet18(n_classes=9, rgb=True)\n",
    "net = net.to(torch.float)\n",
    "if use_cuda:\n",
    "    print('converting network to cuda-enabled')\n",
    "    net.cuda()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z2YDbc4-b_S8"
   },
   "source": [
    "# Converts tensors to cuda, if available\n",
    "def get_variable(x):\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jgCFbJtScCUP"
   },
   "source": [
    "# Get numpy array for both cuda and not\n",
    "def get_numpy(x):\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gDQQPp1Fj4bI"
   },
   "source": [
    "# Create lossfunction and optimizer\n",
    "criterion = UNet.DiceLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=5e-5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lzAyPTbGj4bI"
   },
   "source": [
    "# Define hyper parameters\n",
    "NUM_EPOCHS = 141\n",
    "check_at = 20"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2iU8f0bjxHe7"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i-kf5NL87wHI"
   },
   "source": [
    "# Define list to stor intermediat results\n",
    "valid_iter = []\n",
    "valid_loss = []\n",
    "valid_iou = []\n",
    "\n",
    "train_iter = []\n",
    "train_loss = []\n",
    "train_iou = []\n",
    "\n",
    "# Define data loaders to serve data\n",
    "DL_train = DataLoader(DS_train, batch_size=32, shuffle=True)\n",
    "DL_valid = DataLoader(DS_valid)\n",
    "\n",
    "# Training loop\n",
    "net.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(\"train\")\n",
    "    for i, data in enumerate(DL_train, 0):\n",
    "        net.train()\n",
    "        input = data[0].type(torch.FloatTensor)\n",
    "        target = data[1].type(torch.FloatTensor)\n",
    "\n",
    "        # Tranfer to GPU if possible\n",
    "        input = get_variable(input)\n",
    "        target = get_variable(target)\n",
    "\n",
    "        # Train the network\n",
    "        optimizer.zero_grad()\n",
    "        output = net(input)\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save space\n",
    "        del input\n",
    "        del target\n",
    "        del output\n",
    "        del loss\n",
    "\n",
    "    # If we want to evaluate\n",
    "    if epoch % check_at == 0:\n",
    "      net.eval()\n",
    "\n",
    "      with torch.no_grad():\n",
    "        # Evaluate training\n",
    "        train_losses, train_ious, train_batches = 0, 0, 0\n",
    "        for i, data in enumerate(DL_train, 0):\n",
    "          input = data[0].type(torch.FloatTensor)\n",
    "          target = data[1].type(torch.FloatTensor)\n",
    "\n",
    "          # Tranfer to GPU if possible\n",
    "          input = get_variable(input)\n",
    "          target = get_variable(target)\n",
    "          \n",
    "          output = net(input)\n",
    "\n",
    "          # Record performance\n",
    "          train_batches += 1\n",
    "          train_losses += criterion(output, target).item()\n",
    "          train_ious += IoU_score(get_numpy(target), get_numpy(output))\n",
    "\n",
    "          # Save space\n",
    "          del input\n",
    "          del target\n",
    "          del output\n",
    "\n",
    "        train_iter.append(epoch)\n",
    "        train_loss.append(train_losses / train_batches)\n",
    "        train_iou.append(train_ious / train_batches)\n",
    "\n",
    "        # Evaluate validation\n",
    "        val_losses, val_ious, val_batches = 0, 0, 0\n",
    "        once=True\n",
    "        for i, valid_data in enumerate(DL_valid, 0):\n",
    "            input = valid_data[0].type(torch.FloatTensor)\n",
    "            target = valid_data[1].type(torch.FloatTensor)\n",
    "            \n",
    "            # Tranfer to GPU if possible\n",
    "            input = get_variable(input)\n",
    "            target = get_variable(target)\n",
    "            \n",
    "            output = net(input)\n",
    "            if once:\n",
    "              img = one_hot2_2d(get_numpy(output[0]))[0]\n",
    "              img_label = one_hot2_2d(get_numpy(target[0]))[0]\n",
    "              once = False\n",
    "            # Record performance\n",
    "            val_batches += 1\n",
    "            val_losses += criterion(output, target).item()\n",
    "            val_ious += IoU_score(get_numpy(target), get_numpy(output))\n",
    "            # Save space\n",
    "            del input\n",
    "            del target\n",
    "            del output\n",
    "\n",
    "        valid_iter.append(epoch)\n",
    "        valid_loss.append(val_losses / val_batches)\n",
    "        valid_iou.append(val_ious / val_batches)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        fig = plt.figure(figsize=(12,4))\n",
    "        plt.subplot(141)\n",
    "        plt.plot(valid_iter,valid_loss,label='Validation losses')\n",
    "        plt.plot(train_iter,train_loss,label='Training losses')\n",
    "        plt.title('Losses')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(142)\n",
    "        plt.plot(valid_iter,valid_iou,label='Validation IoU\\'s')\n",
    "        plt.plot(train_iter,train_iou,label='Training IoU\\'s')\n",
    "        plt.title('IoU\\'s')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(143)\n",
    "        plt.imshow(img)\n",
    "        plt.title('Prediction made of a validation picture')\n",
    "\n",
    "        plt.subplot(144)\n",
    "        plt.imshow(img_label)\n",
    "        plt.title('Label made of a validation picture')\n",
    "        plt.show()\n",
    "        print(f'At epoch {epoch} Training loss is at {train_loss[-1]} and the IoU is at {train_iou[-1]}%')\n",
    "        print(f'At epoch {epoch} Validation loss is at {valid_loss[-1]} and the IoU is at {valid_iou[-1]}%')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j8UW1Y11YyUb"
   },
   "source": [
    "net.eval()\n",
    "input = X_train[1].reshape([1,3,256,256])\n",
    "input = get_variable(torch.tensor(input).type(torch.FloatTensor))\n",
    "output = net(input)\n",
    "\n",
    "img_label = one_hot2_2d(get_numpy(output)[0])\n",
    "img_pred = one_hot2_2d(Y_train[1])\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(img_label[0])\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(img_pred[0])\n",
    "\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(X_train[1].transpose([2,1,0])-np.min(X_train[1]))\n",
    "plt.show()\n",
    "print(np.max(X_train[1]))\n",
    "print(X_train.shape)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"LoadData.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"mpuuB45S-vI-"},"source":["import numpy as np\n","import glob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gQx_NkG-vI_"},"source":["import numpy.random\n","from matplotlib import pyplot as plt\n","import matplotlib\n","import cv2\n","import time\n","import random\n","import torch\n","from torch.utils.data import DataLoader,Dataset\n","import os\n","import platform"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GPFhi-FY-vJA"},"source":["transforms an image from a random range to range 0-1"]},{"cell_type":"code","metadata":{"id":"r-YwPwUV-vJB"},"source":["def feature_scaling(img):\n","    img = (img - np.min(img)) / (-np.min(img) + np.max(img))\n","    return img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wF4rdk4l-vJB"},"source":["orrect the colors when loading in the data"]},{"cell_type":"code","metadata":{"id":"Zth_3Jg4-vJB"},"source":["def color_correction(img):\n","    img_new = np.zeros(img.shape)\n","    img_new[0,:,:] = img[0,:,:]+ 0.485 / 0.229\n","    img_new[1,:,:] = img[1,:,:] + 0.456 / 0.224\n","    img_new[2,:,:] = img[2,:,:]+ 0.406 / 0.225\n","    return img_new"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WA9263yT-vJC"},"source":["def one_hot2_2d(label):\n","    for i in range(9):\n","        label[i] = label[i]*i\n","    new_label = np.sum(label,axis=0)\n","    new_label.astype(np.uint8)\n","    end_label = np.zeros((1,label.shape[-2],label.shape[-1]))\n","    end_label[0] = new_label\n","    return end_label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RVKMqper4c6"},"source":["\n","def scale(img, label):\n","    if img.shape[0] == 3:\n","        img = img.transpose([2, 1, 0])\n","        rows, cols, _ = img.shape\n","    else:\n","        rows, cols = img.shape\n","\n","    if label.shape[0] == 9:\n","        label = one_hot2_2d(label)\n","    label = label[0]\n","    scaling_factor = random.uniform(0.9, 1.1)\n","    res = cv2.resize(img, (int(scaling_factor * rows), int(scaling_factor * cols)), interpolation=cv2.INTER_LINEAR)\n","    res_label = cv2.resize(label, (int(scaling_factor * rows), int(scaling_factor * cols)),\n","                           interpolation=cv2.INTER_LINEAR)\n","    newimg = np.zeros(img.shape)\n","    newlabel = np.zeros(label.shape)\n","    if res.shape[1] < newimg.shape[1]:\n","        newimg[0:res.shape[0], 0:res.shape[1]] = res\n","        newlabel[0:res.shape[0], 0:res.shape[1]] = res_label\n","    else:\n","        newimg = res[0:newimg.shape[0], 0:newimg.shape[1]]\n","        newlabel = res_label[0:newimg.shape[0], 0:newimg.shape[1]]\n","\n","    newlabel = np.round(newlabel)\n","    if newimg.shape[-1] == 3:\n","        return newimg.transpose([2, 1, 0]), newlabel\n","\n","    else:\n","        return newimg, newlabel\n","\n","\n","# %%\n","\n","def translate(img, label):\n","    if img.shape[0] == 3:\n","        img = img.transpose([2, 1, 0])\n","        rows, cols, _ = img.shape\n","    else:\n","        rows, cols = img.shape\n","    if label.shape[0] == 9:\n","        label = one_hot2_2d(label)\n","    label = label[0]\n","    dx = random.uniform(-30, 30)\n","    dy = random.uniform(-30, 30)\n","    M = np.float32([[1, 0, dx], [0, 1, dy]])\n","    dst = cv2.warpAffine(img, M, (cols, rows))\n","    newlabel = cv2.warpAffine(label, M, (cols, rows))\n","    if dst.shape[-1] == 3:\n","        return dst.transpose([2, 1, 0]), newlabel\n","    else:\n","        return dst, newlabel\n","\n","\n","# %%\n","\n","def rotate(img, label):\n","    if img.shape[0] == 3:\n","        img = img.transpose([2, 1, 0])\n","        rows, cols, _ = img.shape\n","    else:\n","        rows, cols = img.shape\n","    if label.shape[0] == 9:\n","        label = one_hot2_2d(label)\n","\n","    label = label[0]\n","    theta = random.uniform(-20, 20)\n","    M = cv2.getRotationMatrix2D(((cols - 1) / 2.0, (rows - 1) / 2.0), theta, 1)\n","    dst = cv2.warpAffine(img, M, (cols, rows))\n","    newlabel = cv2.warpAffine(label, M, (cols, rows))\n","    if dst.shape[-1] == 3:\n","        return dst.transpose([2, 1, 0]), newlabel\n","    else:\n","        return dst, newlabel\n","\n","\n","# %%\n","\n","def shear(img, label):\n","    if img.shape[0] == 3:\n","        img = img.transpose([2, 1, 0])\n","        rows, cols, _ = img.shape\n","    else:\n","        rows, cols = img.shape\n","    if label.shape[0] == 9:\n","        label = one_hot2_2d(label)\n","    label = label[0]\n","\n","    shx = random.uniform(-0.1, 0.1)\n","    shy = random.uniform(-0.1, 0.1)\n","    M = np.float32([[1, shx, 0],\n","                    [shy, 1, 0],\n","                    [0, 0, 1]])\n","    # M = cv2.getAffineTransform(pts1, pts2)\n","    dst = cv2.warpPerspective(img, M, (cols, rows))\n","    newlabel = cv2.warpPerspective(label, M, (cols, rows))\n","    if dst.shape[-1] == 3:\n","        return dst.transpose([2, 1, 0]), newlabel\n","    else:\n","        return dst, newlabel\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KRT94LUs-vJC"},"source":["et all transformation functions"]},{"cell_type":"code","metadata":{"id":"MIDth7bJ-vJF"},"source":["def one_hot_encode(img=None, imgs=None):\n","    if img is None:\n","        num_pict = imgs.shape[0]\n","        Y = np.zeros((num_pict, 9, 256, 256))\n","        imgs = np.round(imgs)\n","        imgs = imgs.astype('int8')\n","        for i in range(num_pict):\n","            for j in range(9):\n","                Y[i, j, :, :] = np.where(imgs[i] == j, 1, 0)\n","    elif imgs is None:\n","        Y = np.zeros((9, 256, 256))\n","        img = np.round(img)\n","        img = img.astype('int8')\n","        for j in range(9):\n","            #\n","            Y[ j, :, :] = np.where(img == j, 1, 0)\n","    else:\n","        raise Exception('only one of the two may be given')\n","    return Y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YnBT-XoX_hMa"},"source":["def load_data_2np(hot_encoding=False,valid_perc=0.1,train_perc=1.0,CAD_perc=0.2,show=0,background=True):\n","    \"\"\"\n","    :param folder: str: relative path to your car_segmentation_2021 folder\n","    :param percentage: float: how many in percentage yopu want to load\n","    :param hot_encoding: if set to true target will be onehotencoded instead of containing numbers from 0-8\n","    :return: input and target\n","    \"\"\"\n","\n","    def assign_to_array(num_pict, datalst):\n","        X = np.zeros((num_pict, 3, 256, 256))\n","        if hot_encoding:\n","            Y = np.zeros((num_pict, 9, 256, 256))\n","        else:\n","            Y = np.zeros((num_pict, 1, 256, 256))\n","\n","        # read all data and assign to the right arrays\n","        for i in range(num_pict):\n","            img = np.load(datalst[i])\n","\n","            imgx, imgy = img[0:3], img[-1]\n","            X[i, :, :, :] = color_correction(imgx[:, :, :])\n","\n","            if hot_encoding:\n","                for j in range(9):\n","                    imgy.astype('int8')\n","                    Y[i, j, :, :] = np.where(imgy == j, 1, 0)\n","            else:\n","                Y[i, :, :, :] = imgy\n","        return X,Y\n","\n","    # get OS\n","    OS = platform.system().lower()\n","    #get list of all clean datafiles\\\n","    folder = os.getenv('DEEP_DATA')\n","    if OS == 'windows':\n","        if background:\n","            train_folder_real = folder + '\\\\with_background\\\\train_real\\\\'\n","            test_folder = folder + '\\\\with_background\\\\test\\\\'\n","            train_folder_cad = folder + '\\\\with_background\\\\train_CAD\\\\'\n","            train_folder_trans = folder + '\\\\with_background\\\\train_transforms\\\\'\n","        else:\n","            train_folder_real = folder + '\\\\without_background\\\\train_real\\\\'\n","            test_folder = folder + '\\\\without_background\\\\test\\\\'\n","            train_folder_cad = folder + '\\\\without_background\\\\train_CAD\\\\'\n","            train_folder_trans = folder + '\\\\without_background\\\\train_transforms\\\\'\n","    elif OS == 'darwin' or OS == 'linux':\n","        if background:\n","            train_folder_real = folder + '/with_background/train_real/'\n","            test_folder = folder + '/with_background/test/'\n","            train_folder_cad = folder + '/with_background/train_CAD/'\n","            train_folder_trans = folder + '/with_background/train_transforms/'\n","        else:\n","            train_folder_real = folder + '/without_background/train_real/'\n","            test_folder = folder + '/without_background/test/'\n","            train_folder_cad = folder + '/without_background/train_CAD/'\n","            train_folder_trans = folder + '/without_background/train_transforms/'\n","    else:\n","        raise Exception(\"Your OS is not accepted.\")\n","\n","    testlst = glob.glob(f'{test_folder}*')\n","    trainlst_real = glob.glob(f'{train_folder_real}*')\n","    trainlst_cad = glob.glob(f'{train_folder_cad}*')\n","    trainlst_trans = glob.glob(f'{train_folder_trans}*')\n","\n","    # randomise the data list in order to have a varied validationlst\n","    # random.seed(456)\n","    random.shuffle(testlst)\n","    random.shuffle(trainlst_real)\n","    random.shuffle(trainlst_cad)\n","    random.shuffle(trainlst_trans)\n","\n","    datalst = trainlst_real+trainlst_cad[0:int(CAD_perc*len(trainlst_cad))]\n","    datalst = datalst[0:int(train_perc*len(datalst))]\n","\n","    num_valid = int(len(datalst) * valid_perc)\n","    num_train = int(len(datalst) - num_valid)\n","\n","    # assign the pictures to the right arrays\n","    X_train,Y_train = assign_to_array(num_pict=num_train,datalst=datalst[0:num_train])\n","    X_valid,Y_valid = assign_to_array(num_pict=num_valid,datalst=datalst[num_train::])\n","    X_trans,Y_trans = assign_to_array(num_pict=len(trainlst_trans),datalst=trainlst_trans)\n","    X_test,Y_test = assign_to_array(num_pict=len(testlst),datalst=testlst)\n","\n","    for i in range(show):\n","        img = X_train[i].transpose([2,1,0])\n","        img = feature_scaling(img)\n","        cv2.imshow('loading', img)\n","        cv2.waitKey(0)\n","        cv2.destroyAllWindows()\n","\n","\n","    return X_train,Y_train,X_valid,Y_valid, X_trans,Y_trans ,X_test,Y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MFw6CrjRJk2"},"source":["class CustomDataset(Dataset):\n","    def __init__(self, data, labels, transform_arr=None, transform_labels=None, one_hot=False):\n","        if transform_arr is None:\n","            self.trans = data.copy()\n","            self.trans_labels = labels.copy()\n","        else:\n","            self.trans = transform_arr\n","            self.trans_labels = transform_labels\n","        self.labels = labels\n","        self.data = data\n","        self.grayed = False\n","        self.one_hot = one_hot\n","        # self.backupx = data.copy()\n","        # self.backupy = labels.copy()\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        label = self.labels[idx]\n","        data = self.data[idx]\n","        return data, label\n","\n","    def grayscale(self):\n","        self.grayed = True\n","\n","        img_arr = np.zeros([self.data.shape[0] + self.trans.shape[0]] + list(self.data.shape[1::]))\n","\n","        img_arr[0:self.data.shape[0]] = self.data.copy()\n","        img_arr[self.data.shape[0]::] = self.trans.copy()\n","        self.data = np.zeros([self.data.shape[0], 1, self.data.shape[2], self.data.shape[3]])\n","        self.trans = np.zeros([self.trans.shape[0], 1, self.trans.shape[2], self.trans.shape[3]])\n","        for i in range(len(img_arr)):\n","            img_arr[i] = feature_scaling(img_arr[i])\n","            img = 0.299 * img_arr[i, 0] + 0.587 * img_arr[i, 1] + 0.114 * img_arr[i, 2]\n","            img = feature_scaling(img)\n","            if i < self.data.shape[0]:\n","                self.data[i, 0] = img\n","            else:\n","                self.trans[i - self.data.shape[0], 0] = img\n","\n","    def gray_gamma(self, gamma=1.2, show=0):\n","        \"\"\"\n","        this functions raises every individual pixel to a desired power. positive gammas enlarges contrast at brighter parts, lower gammas enlar contrast for the darker parts\n","        :param gamma: the exponent\n","        :param show: default is false if true it will show every picture to evaluate it yourself, shut the program manually after seen the desired amount.\n","        \"\"\"\n","        self.grayed = True\n","\n","        img_arr = np.zeros([self.data.shape[0] + self.trans.shape[0]] + list(self.data.shape[1::]))\n","\n","        img_arr[0:self.data.shape[0]] = self.data.copy()\n","        img_arr[self.data.shape[0]::] = self.trans.copy()\n","        self.data = np.zeros([self.data.shape[0], 1, self.data.shape[2], self.data.shape[3]])\n","        self.trans = np.zeros([self.trans.shape[0], 1, self.trans.shape[2], self.trans.shape[3]])\n","        for i in range(len(img_arr)):\n","            img_arr[i] = feature_scaling(img_arr[i])\n","            img = 0.299 * img_arr[i, 0] + 0.587 * img_arr[i, 1] + 0.114 * img_arr[i, 2]\n","            img = feature_scaling(img)\n","            img = img ** (gamma)\n","            if i < self.data.shape[0]:\n","                self.data[i, 0] = img\n","            else:\n","                self.trans[i - self.data.shape[0], 0] = img\n","\n","            if i < show:\n","                cv2.imshow('', img)\n","                cv2.waitKey(0)\n","                cv2.destroyAllWindows()\n","\n","    def gray_gamma_enhanced(self, show=0, method='log', a=-1):\n","        \"\"\"\n","        this functions raises every individual pixel to a desired power. positive gammas enlarges contrast at brighter parts, lower gammas enlar contrast for the darker parts\n","        Difference with normal gamma is that this functions determines a gamma for every image based on their avarage pixel values\n","        a is used to scale the gammas. negative a means that average dark picture will will get increased contrast lighter part end vice versa.\n","        :param a: gamma = a*gamma+b (with condition that b=1-1/2*a) only used if method is linear\n","        :param method is a string can be linear or log if log the arg a is neglected and gamma is defined to get the average to 0.5\n","        :param show: default is false if true it will show every picture to evaluate it yourself, shut the program manually after seen the desired amount.\n","        \"\"\"\n","        self.grayed = True\n","\n","        method = method.lower()\n","        b = 1 - (0.5 * a)\n","        img_arr = np.zeros([self.data.shape[0] + self.trans.shape[0]] + list(self.data.shape[1::]))\n","        img_arr[0:self.data.shape[0]] = self.data.copy()\n","        img_arr[self.data.shape[0]::] = self.trans.copy()\n","        self.data = np.zeros([self.data.shape[0], 1, self.data.shape[2], self.data.shape[3]])\n","        self.trans = np.zeros([self.trans.shape[0], 1, self.trans.shape[2], self.trans.shape[3]])\n","        for i in range(len(img_arr)):\n","            img_arr[i] = feature_scaling(img_arr[i])\n","            img = 0.299 * img_arr[i, 0] + 0.587 * img_arr[i, 1] + 0.114 * img_arr[i, 2]\n","            img = feature_scaling(img)\n","            mu = img.mean()\n","            if method == 'linear':\n","                gamma = a * mu + b\n","            elif method == 'log':\n","                gamma = np.log(0.5) / np.log(mu)\n","            else:\n","                raise Exception(f'method must be \\'log\\' or \\'linear\\' instead of{method}')\n","            img = img ** (gamma)\n","\n","            if i < self.data.shape[0]:\n","                self.data[i, 0] = img\n","            else:\n","                self.trans[i - self.data.shape[0], 0] = img\n","            if i < show:\n","                cv2.imshow('', img)\n","                cv2.waitKey(0)\n","                cv2.destroyAllWindows()\n","\n","                cv2.imshow('', self.labels[i, 0])\n","                cv2.waitKey(0)\n","                cv2.destroyAllWindows()\n","\n","    def gray_log(self, show=0):\n","        \"\"\"\n","        This will increase contrast of the darker colors.\n","        :param show: default is false if true it will show every picture to evaluate it yourself, shut the program manually after seen the desired amount.\n","        \"\"\"\n","        self.grayed = True\n","\n","        img_arr = np.zeros([self.data.shape[0] + self.trans.shape[0]] + list(self.data.shape[1::]))\n","\n","        img_arr[0:self.data.shape[0]] = self.data.copy()\n","        img_arr[self.data.shape[0]::] = self.trans.copy()\n","        self.data = np.zeros([self.data.shape[0], 1, self.data.shape[2], self.data.shape[3]])\n","        self.trans = np.zeros([self.trans.shape[0], 1, self.trans.shape[2], self.trans.shape[3]])\n","\n","        for i in range(len(img_arr)):\n","            img_arr[i] = feature_scaling(img_arr[i])\n","            img = 0.299 * img_arr[i, 0] + 0.587 * img_arr[i, 1] + 0.114 * img_arr[i, 2]\n","            img = feature_scaling(img)\n","            img = np.log(1 + img) / (np.log(1 + img.max()))\n","            if i < self.data.shape[0]:\n","                self.data[i, 0] = img\n","            else:\n","                self.trans[i - self.data.shape[0], 0] = img\n","\n","            if i < show:\n","                cv2.imshow('', img)\n","                cv2.waitKey(0)\n","                cv2.destroyAllWindows()\n","\n","    def get_edges(self, show=False, merged=False):\n","\n","        # elementwise multiplication followed by summation\n","        def apply_kernel(img, kernel):\n","            img = cv2.filter2D(img, -1, kernel)\n","            return img\n","\n","        # if data is not yet grayscaled do this\n","        if not self.grayed:\n","            self.grayscale()\n","\n","        # define kernels to detect edges\n","        kernel_l2r = np.array([[-2, 0, 2],\n","                               [-2, 0, 2],\n","                               [-2, 0, 2]])\n","        kernel_r2l = np.array([[2, 0, -2],\n","                               [2, 0, -2],\n","                               [2, 0, -2]])\n","        # kernel_t2b = np.array([[-2, -2, -2],\n","        #                        [0, 0, 0],\n","        #                        [2, 2, 2]])\n","        # kernel_b2t = np.array([[2, 2, 2],\n","        #                        [0, 0, 0],\n","        #                        [-2, -2, -2]])\n","\n","        # define new data array to hold the grey image and the four edge detected images for decent use with dataloader\n","        if merged:\n","            new_dat = np.zeros([self.data.shape[0] + self.trans.shape[0], 2, self.data.shape[-2], self.data.shape[-1]])\n","        else:\n","            new_dat = np.zeros([self.data.shape[0] + self.trans.shape[0], 3, self.data.shape[-2], self.data.shape[-1]])\n","\n","        img_arr = np.zeros([self.data.shape[0] + self.trans.shape[0]] + list(self.data.shape[1::]))\n","        img_arr[0:self.data.shape[0]] = self.data.copy()\n","        img_arr[self.data.shape[0]::] = self.trans.copy()\n","        self.data = np.zeros([self.data.shape[0], self.data.shape[1], self.data.shape[2]])\n","        self.trans = np.zeros([self.trans.shape[0], self.trans.shape[1], self.trans.shape[2]])\n","\n","        for i in range(len(img_arr)):\n","            for idx, kernel in enumerate([kernel_l2r, kernel_r2l]):\n","                if merged:\n","                    img = img_arr[i]\n","                    img = apply_kernel(img, kernel)\n","                    img = feature_scaling(img)\n","                    img_arr[i] = img\n","                else:\n","                    img = img_arr[i]\n","                    img = apply_kernel(img, kernel)\n","                    img = feature_scaling(img)\n","\n","                    new_dat[i, idx + 1] = img\n","\n","                if i < show:\n","                    cv2.imshow('', img)\n","                    cv2.waitKey(0)\n","                    cv2.destroyAllWindows()\n","            if merged:\n","                new_dat[i, 1] = img_arr[i]\n","\n","        self.data = new_dat[0:self.data.shape[0]]\n","        self.trans = new_dat[self.data.shape[0]::]\n","\n","    def transforms(self, p_rot=0.1, p_trans=0.1, p_zoom=0.1, p_shear=0.1, show=0):\n","        #get exact number of desired transforms\n","        num_rot = int(p_rot * self.data.shape[0])\n","        num_trans = int(p_trans * self.data.shape[0])\n","        num_zoom = int(p_zoom * self.data.shape[0])\n","        num_shear = int(p_shear * self.data.shape[0])\n","        amount_trans = num_rot+num_trans+num_zoom+num_shear\n","        iter =0\n","        #make array for transforms and to copy data into\n","        copied_dat = self.data.copy()\n","        copied_lab = self.labels.copy()\n","        transform_dat = np.zeros(([amount_trans]+list(self.data.shape[1::])))\n","        transform_lab = np.zeros(([amount_trans]+list(self.labels.shape[1::])))\n","\n","        #get random indexes\n","        idx_dat = list(range(self.data.shape[0]))\n","        random.shuffle(idx_dat)\n","        idxlst_rot = idx_dat[0:num_rot]\n","        idxlst_trans = idx_dat[num_rot:num_rot + num_trans]\n","        idxlst_zoom = idx_dat[num_rot + num_trans:num_rot + num_trans + num_zoom]\n","        idxlst_shear = idx_dat[num_rot + num_trans + num_zoom:num_rot + num_trans + num_zoom + num_shear]\n","\n","        #input of figure transforms should be one 3,256,256 or 256,256 and 9,256,256 or 1,256,256 output is\n","        for i,idx in enumerate(idxlst_rot):\n","            if self.grayed:\n","                transform_dat[iter],temp_lab =  rotate(copied_dat[idx,0],copied_lab[idx])\n","            else:\n","                transform_dat[iter], temp_lab = rotate(copied_dat[idx], copied_lab[idx])\n","            if self.one_hot:\n","                transform_lab[iter] = one_hot_encode(img=temp_lab)\n","            else:\n","                transform_lab[iter,0] = temp_lab\n","\n","            iter += 1\n","\n","\n","        for i, idx in enumerate(idxlst_trans):\n","            if self.grayed:\n","                transform_dat[iter], temp_lab = translate(copied_dat[idx, 0], copied_lab[idx])\n","            else:\n","                transform_dat[iter], temp_lab = translate(copied_dat[idx], copied_lab[idx])\n","            if self.one_hot:\n","                transform_lab[iter] = one_hot_encode(img=temp_lab)\n","            else:\n","                transform_lab[iter, 0] = temp_lab\n","\n","            iter += 1\n","\n","        for i, idx in enumerate(idxlst_zoom):\n","            if self.grayed:\n","                transform_dat[iter], temp_lab = scale(copied_dat[idx, 0], copied_lab[idx])\n","            else:\n","                transform_dat[iter], temp_lab = scale(copied_dat[idx], copied_lab[idx])\n","            if self.one_hot:\n","                transform_lab[iter] = one_hot_encode(img=temp_lab)\n","            else:\n","                transform_lab[iter, 0] = temp_lab\n","\n","            iter += 1\n","\n","        for i, idx in enumerate(idxlst_shear):\n","            if self.grayed:\n","                transform_dat[iter], temp_lab = shear(copied_dat[idx, 0], copied_lab[idx])\n","            else:\n","                transform_dat[iter], temp_lab = shear(copied_dat[idx], copied_lab[idx])\n","            if self.one_hot:\n","                transform_lab[iter] = one_hot_encode(img=temp_lab)\n","            else:\n","                transform_lab[iter, 0] = temp_lab\n","\n","            iter += 1\n","\n","        #combine two array into one!\n","        self.data = np.concatenate((transform_dat,copied_dat),axis=0)\n","        self.labels = np.concatenate((transform_lab, copied_lab), axis=0)\n","        self.amount_transforms = amount_trans\n","\n","    def remove_transforms(self):\n","\n","        self.labels = self.trans_labels.copy()\n","        self.data = self.trans.copy()\n","        self.amount_transforms = 0\n","\n","    def add_transforms(self, p_trans=None, number_trans=None):\n","        if self.trans is not False:\n","            index_list = list(range(self.trans.shape[0]))\n","            random.shuffle(index_list)\n","\n","            # get the desired amount of transformations\n","            if p_trans is None and number_trans is None:\n","                Exception('p_trans or number_trans should be set to a number')\n","                amount = 0\n","            elif p_trans is not None:\n","                amount = int(p_trans * len(index_list))\n","            else:\n","                amount = number_trans\n","\n","            # check that amount is lower than the length of the list\n","            amount = min(amount, len(index_list))\n","\n","            # get random transformed images and add them tyo the self.data variable\n","            newdat = np.zeros([amount + self.data.shape[0]] + list(self.data.shape[1::]))\n","            newlab = np.zeros([amount + self.labels.shape[0]] + list(self.labels.shape[1::]))\n","            index_list = index_list[0:amount]\n","            for iter, idx in enumerate(index_list):\n","                newdat[iter] = self.trans[idx]\n","                newlab[iter] = self.trans_labels[idx]\n","\n","            newlab = newlab.astype('uint8')\n","            newdat[amount::] = self.data.copy()\n","            newlab[amount::] = self.labels.copy()\n","            self.data = newdat.copy()\n","            self.labels = newlab.copy()\n","            self.amount_transforms = amount\n","        else:\n","            raise Exception('To use this function you need to give a transforms array as an input.')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i2feQqnD-vJJ"},"source":["def test_pics(example_feat):\n","    for i in range(8):\n","        img = example_feat[i].numpy().transpose([2, 1, 0])\n","        imgC1, imgC2, imgC3 = feature_scaling(img)[:, :, 0], feature_scaling(img)[:, :, 1], feature_scaling(img)[:, :, 2]\n","        img[:, :, 0], img[:, :, 1], img[:, :, 2] = imgC1, imgC2, imgC3\n","        cv2.imshow('', img)\n","        cv2.waitKey(0)\n","        cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IWYGWfSBRQ_i","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1638529517751,"user_tz":-60,"elapsed":67,"user":{"displayName":"Carpentier Oscar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02229027416844024711"}},"outputId":"cdd4a8e8-c10c-407a-c35c-802434dffece"},"source":["if __name__ == '__main__':\n","    # start a timer to see execution time\n","    start_time = time.time()\n","\n","\n","    #or do it yourself:\n","    #load in the data as np arrays (to just check it use a low train_perc to reduce runtime)\n","    X_train, Y_train, X_valid, Y_valid, X_trans, Y_trans, X_test, Y_test = load_data_2np(hot_encoding=True, valid_perc=0.1, train_perc=0.1,show=0,CAD_perc=0,background=True)\n","\n","    print(X_train.shape,Y_train.shape)\n","\n","    #change the data into a dataset object in order to use DataLoader functionality\n","    DS_train = CustomDataset(X_train,Y_train,one_hot=True)\n","\n","    DS_train.gray_gamma_enhanced(show=0)\n","    DS_train.transforms(show=5)\n","    # DS_train.add_transforms(number_trans=100)\n","    DS_train.remove_transforms()\n","        #DL_train = DataLoader(DS_train,batch_size=8,shuffle=True)\n","    # begin = time.perf_counter()\n","    # for i in range(50):\n","    #     # DS_train.transforms(p_trans=0.05,p_zoom=0.05,p_shear=0.05,p_rot=0.05)\n","    #     DS_train.add_transforms()\n","    #     DL_train = DataLoader(DS_train,batch_size=8,shuffle=True)\n","    #     DS_train.remove_transforms()\n","    # end = time.perf_counter()\n","    # print(f'it took {end-begin} seconds to run') #98.27 seconds to run this with in loop transforms and 74 seconds to load in the transforms beforehand\n","\n","    print(\"--- %s seconds ---\" % (time.time() - start_time))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-d1744938adcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#or do it yourself:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#load in the data as np arrays (to just check it use a low train_perc to reduce runtime)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_2np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhot_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_perc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_perc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCAD_perc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackground\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-5f76bc722e11>\u001b[0m in \u001b[0;36mload_data_2np\u001b[0;34m(hot_encoding, valid_perc, train_perc, CAD_perc, show, background)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mOS\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'darwin'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mOS\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'linux'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mtrain_folder_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/with_background/train_real/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mtest_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/with_background/test/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mtrain_folder_cad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/with_background/train_CAD/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"]}]}]}